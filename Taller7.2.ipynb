{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyO4AZgSRuglW2dwSlAkYnZ4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tommy3072/MineriaDeDatos/blob/main/Taller7.2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import roc_curve, auc, ConfusionMatrixDisplay\n",
        "from sklearn.linear_model import LogisticRegressionCV\n",
        "\n",
        "# Función para generar gráficos ROC\n",
        "def generate_graphs(allPredictions, allLabels, rocFilenamePrefix, classesNames=None, colorsNames=None):\n",
        "    NUM_CLASSES = len(classesNames)\n",
        "    if NUM_CLASSES == 2:\n",
        "        allPositiveScores = []\n",
        "        max_score, min_score, pos_label = allPredictions[0][0], allPredictions[0][0], 0\n",
        "        for prediction in allPredictions:\n",
        "            for i in range(NUM_CLASSES):\n",
        "                if max_score < prediction[i]:\n",
        "                    max_score = prediction[i]\n",
        "                if min_score > prediction[i]:\n",
        "                    min_score = prediction[i]\n",
        "        max_score = max_score + abs(min_score)\n",
        "        min_score = min_score + abs(min_score)\n",
        "        for prediction in allPredictions:\n",
        "            allPositiveScores.append((prediction[pos_label] + abs(min_score)) / (max_score - min_score))\n",
        "\n",
        "        fpr, tpr, _ = roc_curve(allLabels, allPositiveScores, pos_label=pos_label)\n",
        "        auc_score = auc(fpr, tpr)\n",
        "        plt.figure()\n",
        "        graphLabel = 'AUC={0:.3f}'.format(auc_score)\n",
        "        plt.plot(fpr, tpr, color='darkorange', lw=2, label=graphLabel)\n",
        "        plt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.0])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic ')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(rocFilenamePrefix + \"-roc.png\", pad_inches=5)\n",
        "    else:\n",
        "        # Multiclass-case AUCs\n",
        "        roc_auc, fpr, tpr = dict(), dict(), dict()\n",
        "        for i in range(NUM_CLASSES):\n",
        "            max_score, min_score = allPredictions[0][i], allPredictions[0][i]\n",
        "            for prediction in allPredictions:\n",
        "                if max_score < prediction[i]:\n",
        "                    max_score = prediction[i]\n",
        "                if min_score > prediction[i]:\n",
        "                    min_score = prediction[i]\n",
        "            max_score = max_score + abs(min_score)\n",
        "            min_score = min_score + abs(min_score)\n",
        "            allPositiveScores = []\n",
        "            for prediction in allPredictions:\n",
        "                allPositiveScores.append((prediction[i] + abs(min_score)) / (max_score - min_score))\n",
        "            fpr[i], tpr[i], _ = roc_curve(allLabels, allPositiveScores, pos_label=i)\n",
        "            roc_auc[i] = auc(fpr[i], tpr[i])\n",
        "\n",
        "        all_fpr = np.unique(np.concatenate([fpr[i] for i in range(NUM_CLASSES)]))\n",
        "        mean_tpr = np.zeros_like(all_fpr)\n",
        "        for i in range(NUM_CLASSES):\n",
        "            mean_tpr += np.interp(all_fpr, fpr[i], tpr[i])\n",
        "        mean_tpr /= NUM_CLASSES\n",
        "\n",
        "        fpr[\"macro\"], tpr[\"macro\"] = all_fpr, mean_tpr\n",
        "        roc_auc[\"macro\"] = auc(fpr[\"macro\"], tpr[\"macro\"])\n",
        "\n",
        "        plt.figure()\n",
        "        plt.plot(fpr[\"macro\"], tpr[\"macro\"], label='macro-average (AUC={0:0.3f})'.format(roc_auc[\"macro\"]),\n",
        "                 color='navy', linestyle=':', linewidth=4)\n",
        "\n",
        "        if colorsNames is None:\n",
        "            colorsNames = ['aqua', 'darkorange', 'cornflowerblue', 'deeppink']\n",
        "\n",
        "        for i, color in zip(range(NUM_CLASSES), colorsNames):\n",
        "            plt.plot(fpr[i], tpr[i], color=color, lw=2,\n",
        "                     label='{0} (AUC={1:0.3f})'.format(classesNames[i], roc_auc[i]))\n",
        "\n",
        "        plt.plot([0, 1], [0, 1], 'k--', lw=2)\n",
        "        plt.xlim([0.0, 1.0])\n",
        "        plt.ylim([0.0, 1.0])\n",
        "        plt.xlabel('False Positive Rate')\n",
        "        plt.ylabel('True Positive Rate')\n",
        "        plt.title('Receiver Operating Characteristic')\n",
        "        plt.legend(loc=\"lower right\")\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(rocFilenamePrefix + \"-roc.png\", pad_inches=5)\n",
        "\n",
        "# Carga del dataset de crédito\n",
        "df = pd.read_csv(\"credito.csv\")\n",
        "X = df[[\"balance_control\", \"duracion_prestamo\", \"historial_credito\", \"edad\",\n",
        "        \"saldo_ahorro\", \"longitud_empleo\", \"tasa_instalacion\", \"creditos_existentes\"]]\n",
        "y = df[\"monto\"]\n",
        "\n",
        "# División en train/test/eval\n",
        "x_train, x_temp, y_train, y_temp = train_test_split(X, y, test_size=0.4, train_size=0.6)\n",
        "x_test, x_eval, y_test, y_eval = train_test_split(x_temp, y_temp, test_size=0.5, train_size=0.5)\n",
        "\n",
        "# Entrenamiento del modelo\n",
        "model = LogisticRegression(solver='liblinear', random_state=0).fit(x_train, y_train)\n",
        "\n",
        "# Evaluación en conjunto de validación (eval)\n",
        "print(str(model.classes_))\n",
        "print(str(model.predict_proba(x_eval)))\n",
        "print(str(model.predict(x_eval)))\n",
        "\n",
        "cm_1 = confusion_matrix(y_eval, model.predict(x_eval), labels=model.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_1, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lr-eval.png\")\n",
        "print(str(cm_1))\n",
        "print(classification_report(y_eval, model.predict(x_eval)))\n",
        "\n",
        "# Generación de gráfico ROC para el conjunto de validación\n",
        "generate_graphs(model.predict_proba(x_eval), y_eval, \"roc-eval-\", classesNames=model.classes_, colorsNames=None)\n",
        "\n",
        "# Evaluación en conjunto de prueba (test)\n",
        "print(str(model.predict_proba(x_test)))\n",
        "print(str(model.predict(x_test)))\n",
        "\n",
        "cm_2 = confusion_matrix(y_test, model.predict(x_test), labels=model.classes_)\n",
        "disp = ConfusionMatrixDisplay(confusion_matrix=cm_2, display_labels=model.classes_)\n",
        "disp.plot(cmap=plt.cm.Blues, values_format='d')\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"lr-test.png\")\n",
        "print(str(cm_2))\n",
        "print(classification_report(y_test, model.predict(x_test)))\n",
        "\n",
        "# Generación de gráfico ROC para el conjunto de prueba\n",
        "generate_graphs(model.predict_proba(x_test), y_test, \"roc-test-\", classesNames=model.classes_, colorsNames=None)\n",
        "\n",
        "# Cross-validation con 5-folds\n",
        "cv_model = LogisticRegressionCV(cv=5, random_state=0).fit(X, y)\n",
        "print(str(cv_model.predict(X)))\n",
        "print(str(cv_model.predict_proba(X)))\n",
        "print(str(cv_model.score(X, y)))\n",
        "\n",
        "# Generación de gráfico ROC para todo el dataset (cross-validation)\n",
        "generate_graphs(model.predict_proba(X), y, \"roc-cv-\", classesNames=model.classes_, colorsNames=None)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T-KmJnVMAfHF",
        "outputId": "470710e5-0758-4a74-be43-6645c478ad66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[  250   276   338   339   343   362   368   385   392   409   426   428\n",
            "   448   454   458   484   518   571   585   601   609   618   629   639\n",
            "   640   652   654   666   684   701   717   719   727   745   750   754\n",
            "   759   760   763   766   776   783   790   795   802   804   806   841\n",
            "   846   860   866   882   886   888   900   909   915   918   926   929\n",
            "   932   939   958   959   975   976   996  1024  1037  1038  1047  1048\n",
            "  1049  1055  1056  1068  1076  1092  1098  1101  1107  1113  1123  1126\n",
            "  1131  1138  1154  1155  1164  1168  1185  1188  1190  1199  1200  1203\n",
            "  1206  1207  1213  1216  1223  1224  1231  1236  1237  1238  1239  1245\n",
            "  1249  1255  1258  1262  1264  1271  1274  1275  1278  1282  1283  1287\n",
            "  1288  1289  1291  1295  1297  1299  1308  1309  1311  1313  1316  1318\n",
            "  1322  1323  1330  1331  1333  1337  1338  1343  1344  1345  1347  1352\n",
            "  1355  1360  1361  1364  1374  1376  1377  1382  1386  1388  1391  1393\n",
            "  1402  1403  1409  1413  1414  1424  1433  1444  1449  1471  1473  1474\n",
            "  1478  1493  1494  1501  1503  1505  1512  1514  1520  1525  1533  1537\n",
            "  1538  1546  1552  1555  1567  1568  1569  1585  1592  1595  1603  1620\n",
            "  1647  1655  1659  1670  1680  1715  1736  1743  1747  1750  1755  1766\n",
            "  1768  1778  1795  1797  1804  1817  1820  1823  1829  1835  1837  1845\n",
            "  1858  1872  1881  1884  1887  1893  1901  1919  1924  1925  1927  1935\n",
            "  1936  1938  1940  1941  1943  1950  1953  1957  1961  1963  1977  1980\n",
            "  1987  1995  2002  2012  2022  2028  2032  2039  2051  2058  2063  2069\n",
            "  2096  2100  2101  2108  2122  2124  2133  2136  2146  2149  2150  2169\n",
            "  2171  2181  2186  2223  2238  2241  2246  2247  2249  2278  2279  2284\n",
            "  2288  2292  2299  2301  2303  2320  2323  2325  2326  2327  2329  2333\n",
            "  2337  2348  2353  2360  2366  2375  2384  2389  2404  2406  2424  2442\n",
            "  2445  2462  2483  2503  2507  2515  2520  2522  2538  2569  2570  2576\n",
            "  2577  2578  2580  2600  2603  2611  2613  2622  2629  2631  2662  2671\n",
            "  2679  2684  2687  2697  2712  2743  2745  2746  2753  2762  2764  2767\n",
            "  2782  2825  2828  2831  2835  2848  2872  2896  2899  2901  2910  2923\n",
            "  2924  2930  2964  2978  2991  2993  2996  3016  3017  3021  3029  3031\n",
            "  3049  3051  3059  3062  3069  3074  3104  3105  3114  3123  3124  3148\n",
            "  3160  3181  3213  3234  3235  3244  3275  3342  3345  3357  3368  3384\n",
            "  3394  3399  3414  3422  3441  3446  3447  3448  3488  3496  3499  3509\n",
            "  3518  3527  3535  3552  3565  3566  3573  3577  3578  3590  3599  3609\n",
            "  3612  3617  3620  3621  3622  3650  3660  3676  3749  3763  3777  3804\n",
            "  3812  3832  3835  3857  3863  3868  3872  3913  3914  3939  3959  3966\n",
            "  3973  3976  3979  3990  4006  4020  4057  4113  4153  4169  4210  4249\n",
            "  4272  4280  4308  4351  4370  4380  4439  4454  4473  4530  4591  4623\n",
            "  4657  4675  4679  4686  4716  4771  4788  4795  4796  4811  4817  4843\n",
            "  4870  5045  5084  5096  5103  5129  5152  5234  5248  5293  5302  5324\n",
            "  5433  5507  5511  5595  5711  5742  5743  5771  5801  5842  5848  5943\n",
            "  5951  5965  5998  6070  6110  6187  6224  6314  6361  6416  6419  6458\n",
            "  6468  6560  6579  6614  6758  6761  6842  6850  6872  6948  6967  6999\n",
            "  7127  7166  7374  7409  7432  7476  7511  7582  7596  7629  7721  7814\n",
            "  7824  7865  7882  7966  7980  8065  8133  8229  8613  8978  9034  9157\n",
            "  9271  9283  9398  9436  9566 10127 10222 10297 10366 10722 10875 10961\n",
            " 11328 11560 11760 11938 11998 12169 12204 12612 12680 12976 13756 14027\n",
            " 14179 14318 14421 14896 15653 15672 15857 18424]\n",
            "[[1.27135370e-07 3.74923123e-06 7.09272906e-10 ... 6.06833829e-06\n",
            "  8.37865549e-04 2.47977170e-04]\n",
            " [2.10679476e-03 2.81966594e-05 7.63669590e-04 ... 1.94472181e-06\n",
            "  4.88673879e-05 1.14667407e-04]\n",
            " [6.41966961e-05 8.16420638e-03 1.71326992e-05 ... 2.26590053e-04\n",
            "  1.77804160e-04 6.59712721e-05]\n",
            " ...\n",
            " [3.17080906e-04 1.17807342e-04 3.14821545e-06 ... 3.63504618e-05\n",
            "  1.21983167e-05 2.24427637e-04]\n",
            " [9.62402003e-09 4.83212277e-04 6.34366159e-11 ... 1.62143666e-03\n",
            "  8.12367281e-04 5.82991779e-04]\n",
            " [4.26264000e-05 4.50562936e-03 1.80012709e-05 ... 1.11795125e-04\n",
            "  1.58041326e-04 5.16821064e-05]]\n",
            "[ 1258   717  1275  1386  4473  2169  3959  2507  1126  1199  1585  2835\n",
            "   802  1919  2835  6314  1552 14318  1238  9157  2284  2333 10127  3049\n",
            "  1940  1352  1386  2764  1393  1715  2032  1503  1393  1199  1919  1919\n",
            "  1533  1845  1478  2333  6416  6314 10297  3979  3872  6842  5433  1386\n",
            "  1533  1995  4272  3959  1386  2442  1386  1503  2181  2133  1845  1845\n",
            "  1333  3914  1264  5293  1382  3959 13756  1977  2743  1845  1503   783\n",
            "  1333  3394  2320  1743  1264  2671  4370   760  2580  3835  6224  1164\n",
            "  1503  7980  2146  1190  1364  6416 12204  1595  1164  1533  3049  1393\n",
            "  6187  2299  6314  5152  1478  2039  1190  1503  2320  7629  5842  1533\n",
            "  4272  5771  2538  1382  5433   802  7596  3394 12976  1533  6614   717\n",
            "  2899  1275  3872 10297  6842  2924  2326  4811   717 10366   802  1533\n",
            "  3979  1393  1409  3275   790  7629  6224   338  2406  4591  6761  1264\n",
            "  1239  1533 15857   783  9283  1963  3959  1927  3059  1275  1393  7980\n",
            "  6416  3959  1533  2320  1845  7582  1503   802  5433  3488  1393  2899\n",
            "   846   701  5324  7432  1585   571  7409  3031  1919 13756  2333  3959\n",
            "   701  1199  3872  1190  1887  3394  3059  2288  6416  5152  7596  3959\n",
            "  1478   750  7432  1098  3959  6070  4473  1275]\n"
          ]
        }
      ]
    }
  ]
}